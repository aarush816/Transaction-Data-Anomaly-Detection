{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d857de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully at: E:\\transactions_march.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to generate random data for trade count and quote count\n",
    "def generate_random_trade_count():\n",
    "    return random.randint(0, 50)\n",
    "\n",
    "def generate_random_quote_count():\n",
    "    return random.randint(0, 50)\n",
    "\n",
    "# Define headers and possible values\n",
    "headers = [\"timestamp\", \"content name\", \"environment\", \"lineID\", \"trade count\", \"quote count\"]\n",
    "environments = [\"qa\", \"pt\", \"dr\", \"pr\"]\n",
    "content_names = [\"onl\", \"fut\", \"otc\", \"wth\"]\n",
    "\n",
    "# Define lineID ranges for each content name\n",
    "lineID_ranges = {\n",
    "    \"onl\": list(range(101, 105)),\n",
    "    \"fut\": list(range(105, 109)),\n",
    "    \"otc\": list(range(109, 113)),\n",
    "    \"wth\": list(range(113, 117))\n",
    "}\n",
    "\n",
    "# Define start and end times for the period\n",
    "start_date = datetime(2024, 3, 1, 6, 30, 0)\n",
    "end_date = datetime(2024, 3, 30, 13, 30, 0)\n",
    "\n",
    "data = []\n",
    "\n",
    "# Generate timestamps and data for each minute from 6:30 AM to 1:30 PM for each day of March 2024\n",
    "for timestamp in range(int(start_date.timestamp()), int(end_date.timestamp()) + 1, 60):  # Increment timestamp by 60 seconds\n",
    "    for content_name in content_names:\n",
    "        for lineID in lineID_ranges[content_name]:\n",
    "            trade_count = generate_random_trade_count()\n",
    "            quote_count = generate_random_quote_count()\n",
    "            \n",
    "            # Ensure same trade and quote counts for different environments\n",
    "            same_trade_count = trade_count  \n",
    "            same_quote_count = quote_count\n",
    "            \n",
    "            for environment in environments:\n",
    "                data.append([timestamp, content_name, environment, lineID, same_trade_count, same_quote_count])\n",
    "# Specify the file path\n",
    "file_path =r\"E:\\transactions_march.csv\"\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file generated successfully at: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728cb34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>content name</th>\n",
       "      <th>environment</th>\n",
       "      <th>lineID</th>\n",
       "      <th>trade count</th>\n",
       "      <th>quote count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709254800</td>\n",
       "      <td>onl</td>\n",
       "      <td>qa</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709254800</td>\n",
       "      <td>onl</td>\n",
       "      <td>pt</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1709254800</td>\n",
       "      <td>onl</td>\n",
       "      <td>dr</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1709254800</td>\n",
       "      <td>onl</td>\n",
       "      <td>pr</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1709254800</td>\n",
       "      <td>onl</td>\n",
       "      <td>qa</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp content name environment  lineID  trade count  quote count\n",
       "0  1709254800          onl          qa     101           16            8\n",
       "1  1709254800          onl          pt     101           16            8\n",
       "2  1709254800          onl          dr     101           16            8\n",
       "3  1709254800          onl          pr     101           16            8\n",
       "4  1709254800          onl          qa     102           44           47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = r\"E:\\transactions_march.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82b076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp        int64\n",
      "content name    object\n",
      "environment     object\n",
      "lineID           int64\n",
      "trade count      int64\n",
      "quote count      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46e97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully at: E:\\transactions_march31.csv\n"
     ]
    }
   ],
   "source": [
    "# Define start and end times for the period\n",
    "start_date = datetime(2024, 3, 31, 6, 30, 0)\n",
    "end_date = datetime(2024, 3, 31, 13, 30, 0)\n",
    "\n",
    "data = []\n",
    "\n",
    "# Generate timestamps and data for each minute from 6:30 AM to 1:30 PM for each day of March 2024\n",
    "for timestamp in range(int(start_date.timestamp()), int(end_date.timestamp()) + 1, 60):  # Increment timestamp by 60 seconds\n",
    "    for content_name in content_names:\n",
    "        for lineID in lineID_ranges[content_name]:\n",
    "            trade_count = generate_random_trade_count()\n",
    "            quote_count = generate_random_quote_count()\n",
    "            \n",
    "            # Ensure same trade and quote counts for different environments\n",
    "            same_trade_count = trade_count  \n",
    "            same_quote_count = quote_count\n",
    "            \n",
    "            for environment in environments:\n",
    "                data.append([timestamp, content_name, environment, lineID, same_trade_count, same_quote_count])\n",
    "# Specify the file path\n",
    "file_path =r\"E:\\transactions_march31.csv\"\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file generated successfully at: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbba7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies checked and updated with correct marking in the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(r\"E:\\transactions_march31.csv\")\n",
    "\n",
    "# Function to mark anomalies within each group\n",
    "def mark_anomalies(group):\n",
    "    # Check if there are discrepancies in 'trade count' or 'quote count' within the group\n",
    "    trade_count_unique = group['trade count'].unique()\n",
    "    quote_count_unique = group['quote count'].unique()\n",
    "    \n",
    "    if len(trade_count_unique) > 1 or len(quote_count_unique) > 1:\n",
    "        # Identify the row with an anomaly and mark it as 1, others as 0\n",
    "        group['anomaly'] = (~group.duplicated(subset=['lineID', 'trade count', 'quote count'], keep=False)).astype(int)\n",
    "    else:\n",
    "        # No anomalies detected within the group, mark all rows as 0\n",
    "        group['anomaly'] = 0\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Collect individual DataFrame groups with anomalies marked\n",
    "group_list = []\n",
    "for _, group_df in df.groupby(['lineID'], sort=False):\n",
    "    marked_group = mark_anomalies(group_df.copy())  # Make a copy to avoid modifying the original DataFrame\n",
    "    group_list.append(marked_group)\n",
    "\n",
    "# Concatenate all groups into a single DataFrame and sort by original index to restore order\n",
    "updated_df = pd.concat(group_list).sort_index()\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "updated_df.to_csv(r\"E:\\anomalies.csv\", index=False)\n",
    "\n",
    "print(\"Anomalies checked and updated with correct marking in the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae8fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly rows saved to 'anomaly_rows.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter the DataFrame to include only rows with anomalies (anomaly == 1)\n",
    "anomaly_df = updated_df[updated_df['anomaly'] == 1]\n",
    "\n",
    "# Save the anomaly rows to a new CSV file\n",
    "anomaly_df.to_csv(r\"E:\\anomaly_rows.csv\", index=False)\n",
    "print(\"Anomaly rows saved to 'anomaly_rows.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f6ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
